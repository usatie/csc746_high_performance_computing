Successfully paused profiling.
ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 1
==PROF== Connected to process 1801935 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 1
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 1 blocks, 32 threads per block 
 Elapsed time is : 94.555320 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1801935
[1801935] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.04
    gpu__time_duration.avg                                    msecond       451.66
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.23
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle  494,551,753
    Memory Throughput                   %         0.21
    DRAM Throughput                     %         0.04
    Duration                      msecond       451.66
    L1/TEX Cache Throughput             %        20.39
    L2 Cache Throughput                 %         0.21
    SM Active Cycles                cycle 4,579,250.69
    Compute (SM) Throughput             %         0.03
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread              32
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%                                                                                     
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp            1
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%                                                                                     
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,941
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 4
==PROF== Connected to process 1802115 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 4
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 4 blocks, 32 threads per block 
 Elapsed time is : 25.261316 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802115
[1802115] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.16
    gpu__time_duration.avg                                    msecond       115.13
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.91
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle  126,074,349
    Memory Throughput                   %         0.81
    DRAM Throughput                     %         0.16
    Duration                      msecond       115.13
    L1/TEX Cache Throughput             %        20.36
    L2 Cache Throughput                 %         0.84
    SM Active Cycles                cycle 4,583,840.81
    Compute (SM) Throughput             %         0.13
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             128
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%                                                                                      
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp         1.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%                                                                                     
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,950
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 16
==PROF== Connected to process 1802184 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 16
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 16 blocks, 32 threads per block 
 Elapsed time is : 7.980911 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802184
[1802184] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (16, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.57
    gpu__time_duration.avg                                    msecond        31.05
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.38
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   34,002,880
    Memory Throughput                   %         2.99
    DRAM Throughput                     %         0.57
    Duration                      msecond        31.05
    L1/TEX Cache Throughput             %        20.28
    L2 Cache Throughput                 %         3.10
    SM Active Cycles                cycle 4,603,408.96
    Compute (SM) Throughput             %         0.49
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             512
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%                                                                                     
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp            1
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%                                                                                     
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,986
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 64
==PROF== Connected to process 1802249 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 64
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 64 blocks, 32 threads per block 
 Elapsed time is : 3.381942 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802249
[1802249] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (64, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.08
    gpu__time_duration.avg                                    msecond         8.63
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        12.26
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    9,438,451
    Memory Throughput                   %        10.78
    DRAM Throughput                     %         2.08
    Duration                      msecond         8.63
    L1/TEX Cache Throughput             %        20.17
    L2 Cache Throughput                 %        11.00
    SM Active Cycles                cycle 4,629,786.75
    Compute (SM) Throughput             %         1.77
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,048
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%                                                                                     
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         1.56
    Achieved Active Warps Per SM           warp         1.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.88%                                                                                     
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,130
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 256
==PROF== Connected to process 1802294 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 256
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 256 blocks, 32 threads per block 
 Elapsed time is : 2.220073 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802294
[1802294] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (256, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         5.90
    gpu__time_duration.avg                                    msecond         3.09
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        36.14
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    3,381,085
    Memory Throughput                   %        30.08
    DRAM Throughput                     %         5.90
    Duration                      msecond         3.09
    L1/TEX Cache Throughput             %        29.03
    L2 Cache Throughput                 %        30.08
    SM Active Cycles                cycle 3,247,018.77
    Compute (SM) Throughput             %         4.94
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         2.35
    Achieved Active Warps Per SM           warp         1.51
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 95.3%                                                                                      
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (2.4%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,515
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 1024
==PROF== Connected to process 1802358 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 1024
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 1024 blocks, 32 threads per block 
 Elapsed time is : 2.296363 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802358
[1802358] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1024, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         5.89
    gpu__time_duration.avg                                    msecond         3.09
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        36.77
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    3,388,190
    Memory Throughput                   %        29.98
    DRAM Throughput                     %         5.89
    Duration                      msecond         3.09
    L1/TEX Cache Throughput             %        37.80
    L2 Cache Throughput                 %        29.98
    SM Active Cycles                cycle 2,506,243.17
    Compute (SM) Throughput             %         4.93
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          32,768
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         3.11
    Achieved Active Warps Per SM           warp         1.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.78%                                                                                     
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (3.1%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,891,283
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 32 -B 4096
==PROF== Connected to process 1802403 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 32
Command line number of `thread blocks`: 4096
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4096 blocks, 32 threads per block 
 Elapsed time is : 2.232623 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802403
[1802403] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4096, 1, 1)x(32, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         5.90
    gpu__time_duration.avg                                    msecond         3.09
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        36.87
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    3,380,600
    Memory Throughput                   %        30.05
    DRAM Throughput                     %         5.90
    Duration                      msecond         3.09
    L1/TEX Cache Throughput             %        37.80
    L2 Cache Throughput                 %        30.05
    SM Active Cycles                cycle 2,506,987.60
    Compute (SM) Throughput             %         4.94
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    32
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         131,072
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%                                                                                        
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 639 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 93.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           84
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           64
    Theoretical Active Warps per SM        warp           32
    Theoretical Occupancy                     %           50
    Achieved Occupancy                        %         3.11
    Achieved Active Warps Per SM           warp         1.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.78%                                                                                     
          This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM. This   
          kernel's theoretical occupancy (50.0%) is limited by the required amount of shared memory. The difference     
          between calculated theoretical (50.0%) and measured achieved occupancy (3.1%) can be the result of warp       
          scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur between    
          warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide           
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,894,355
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 1
==PROF== Connected to process 1802447 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 1
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 1 blocks, 64 threads per block 
 Elapsed time is : 48.535747 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802447
[1802447] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.07
    gpu__time_duration.avg                                    msecond       244.73
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.46
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle  267,719,611
    Memory Throughput                   %         0.38
    DRAM Throughput                     %         0.07
    Duration                      msecond       244.73
    L1/TEX Cache Throughput             %        38.17
    L2 Cache Throughput                 %         0.40
    SM Active Cycles                cycle 2,480,730.93
    Compute (SM) Throughput             %         0.06
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread              64
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%                                                                                     
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.11
    Achieved Active Warps Per SM           warp         1.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.89%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,944
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 4
==PROF== Connected to process 1802560 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 4
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 4 blocks, 64 threads per block 
 Elapsed time is : 13.863124 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802560
[1802560] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.28
    gpu__time_duration.avg                                    msecond        63.23
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         1.78
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   69,198,496
    Memory Throughput                   %         1.47
    DRAM Throughput                     %         0.28
    Duration                      msecond        63.23
    L1/TEX Cache Throughput             %        38.19
    L2 Cache Throughput                 %         1.53
    SM Active Cycles                cycle 2,480,682.05
    Compute (SM) Throughput             %         0.24
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             256
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%                                                                                      
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.11
    Achieved Active Warps Per SM           warp         1.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.89%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,962
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 16
==PROF== Connected to process 1802629 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 16
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 16 blocks, 64 threads per block 
 Elapsed time is : 5.119309 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802629
[1802629] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (16, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.00
    gpu__time_duration.avg                                    msecond        17.93
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         6.28
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   19,651,633
    Memory Throughput                   %         5.17
    DRAM Throughput                     %         1.00
    Duration                      msecond        17.93
    L1/TEX Cache Throughput             %        38.18
    L2 Cache Throughput                 %         5.34
    SM Active Cycles                cycle 2,481,078.49
    Compute (SM) Throughput             %         0.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%                                                                                     
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.11
    Achieved Active Warps Per SM           warp         1.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.89%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,034
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 64
==PROF== Connected to process 1802696 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 64
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 64 blocks, 64 threads per block 
 Elapsed time is : 2.844661 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802696
[1802696] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (64, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.95
    gpu__time_duration.avg                                    msecond         6.11
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        18.50
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    6,688,560
    Memory Throughput                   %        15.19
    DRAM Throughput                     %         2.95
    Duration                      msecond         6.11
    L1/TEX Cache Throughput             %        38.04
    L2 Cache Throughput                 %        15.25
    SM Active Cycles                cycle 2,490,730.28
    Compute (SM) Throughput             %         2.50
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%                                                                                     
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         3.11
    Achieved Active Warps Per SM           warp         1.99
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 96.89%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (3.1%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,322
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 256
==PROF== Connected to process 1802742 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 256
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 256 blocks, 64 threads per block 
 Elapsed time is : 2.361795 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802742
[1802742] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (256, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         3.78
    gpu__time_duration.avg                                    msecond         4.79
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        26.94
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    5,249,718
    Memory Throughput                   %        19.34
    DRAM Throughput                     %         3.78
    Duration                      msecond         4.79
    L1/TEX Cache Throughput             %        42.46
    L2 Cache Throughput                 %        19.34
    SM Active Cycles                cycle 2,241,316.81
    Compute (SM) Throughput             %         3.18
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          16,384
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         4.38
    Achieved Active Warps Per SM           warp         2.80
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 95.62%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (4.4%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,771
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 1024
==PROF== Connected to process 1802786 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 1024
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 1024 blocks, 64 threads per block 
 Elapsed time is : 2.261011 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802786
[1802786] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1024, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         3.79
    gpu__time_duration.avg                                    msecond         4.81
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        30.41
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    5,260,374
    Memory Throughput                   %        19.29
    DRAM Throughput                     %         3.79
    Duration                      msecond         4.81
    L1/TEX Cache Throughput             %        48.79
    L2 Cache Throughput                 %        19.42
    SM Active Cycles                cycle 1,960,607.99
    Compute (SM) Throughput             %         3.18
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          65,536
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.18
    Achieved Active Warps Per SM           warp         3.95
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.82%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,892,307
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 64 -B 4096
==PROF== Connected to process 1802831 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 64
Command line number of `thread blocks`: 4096
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4096 blocks, 64 threads per block 
 Elapsed time is : 2.272431 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802831
[1802831] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4096, 1, 1)x(64, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         3.80
    gpu__time_duration.avg                                    msecond         4.80
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        32.56
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    5,248,087
    Memory Throughput                   %        19.34
    DRAM Throughput                     %         3.80
    Duration                      msecond         4.80
    L1/TEX Cache Throughput             %        48.78
    L2 Cache Throughput                 %        19.46
    SM Active Cycles                cycle 1,961,025.66
    Compute (SM) Throughput             %         3.19
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                    64
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         262,144
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%                                                                                        
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 639 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 93.8%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           42
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           32
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.18
    Achieved Active Warps Per SM           warp         3.96
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.82%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,898,451
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 1
==PROF== Connected to process 1802896 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 1
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 1 blocks, 128 threads per block 
 Elapsed time is : 26.277501 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802896
[1802896] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.09
    gpu__time_duration.avg                                    msecond       192.77
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.91
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle  211,056,968
    Memory Throughput                   %         0.48
    DRAM Throughput                     %         0.09
    Duration                      msecond       192.77
    L1/TEX Cache Throughput             %        48.89
    L2 Cache Throughput                 %         0.50
    SM Active Cycles                cycle 1,954,676.46
    Compute (SM) Throughput             %         0.08
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             128
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%                                                                                     
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.18
    Achieved Active Warps Per SM           warp         3.96
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.82%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,950
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 4
==PROF== Connected to process 1802965 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 4
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 4 blocks, 128 threads per block 
 Elapsed time is : 8.244930 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1802965
[1802965] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.36
    gpu__time_duration.avg                                    msecond        50.29
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.51
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   55,073,384
    Memory Throughput                   %         1.84
    DRAM Throughput                     %         0.36
    Duration                      msecond        50.29
    L1/TEX Cache Throughput             %        48.92
    L2 Cache Throughput                 %         1.92
    SM Active Cycles                cycle 1,954,200.48
    Compute (SM) Throughput             %         0.30
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             512
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%                                                                                      
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.18
    Achieved Active Warps Per SM           warp         3.96
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.82%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,986
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 16
==PROF== Connected to process 1803031 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 16
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 16 blocks, 128 threads per block 
 Elapsed time is : 3.493479 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803031
[1803031] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (16, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.25
    gpu__time_duration.avg                                    msecond        14.31
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        12.35
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   15,671,037
    Memory Throughput                   %         6.48
    DRAM Throughput                     %         1.25
    Duration                      msecond        14.31
    L1/TEX Cache Throughput             %        48.84
    L2 Cache Throughput                 %         6.68
    SM Active Cycles                cycle 1,958,045.30
    Compute (SM) Throughput             %         1.07
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,048
    Waves Per SM                                                0.01
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%                                                                                     
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.18
    Achieved Active Warps Per SM           warp         3.96
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.82%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,130
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 64
==PROF== Connected to process 1803075 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 64
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 64 blocks, 128 threads per block 
 Elapsed time is : 2.269385 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803075
[1803075] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (64, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         3.79
    gpu__time_duration.avg                                    msecond         4.80
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        36.81
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    5,264,252
    Memory Throughput                   %        19.28
    DRAM Throughput                     %         3.79
    Duration                      msecond         4.80
    L1/TEX Cache Throughput             %        48.79
    L2 Cache Throughput                 %        19.40
    SM Active Cycles                cycle    1,961,011
    Compute (SM) Throughput             %         3.17
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.04
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%                                                                                     
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %         6.18
    Achieved Active Warps Per SM           warp         3.95
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 93.82%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (6.2%) can be the result of warp scheduling overheads    
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,515
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 256
==PROF== Connected to process 1803141 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 256
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 256 blocks, 128 threads per block 
 Elapsed time is : 2.320490 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803141
[1803141] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (256, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.20
    gpu__time_duration.avg                                    msecond         8.22
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        18.56
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    9,033,112
    Memory Throughput                   %        11.28
    DRAM Throughput                     %         2.20
    Duration                      msecond         8.22
    L1/TEX Cache Throughput             %        56.94
    L2 Cache Throughput                 %        11.49
    SM Active Cycles                cycle 1,700,691.66
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          32,768
    Waves Per SM                                                0.15
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        11.85
    Achieved Active Warps Per SM           warp         7.59
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 88.15%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (11.9%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,891,283
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 1024
==PROF== Connected to process 1803185 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 1024
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 1024 blocks, 128 threads per block 
 Elapsed time is : 2.311699 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803185
[1803185] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1024, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.20
    gpu__time_duration.avg                                    msecond         8.24
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        18.45
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    9,017,932
    Memory Throughput                   %        11.30
    DRAM Throughput                     %         2.20
    Duration                      msecond         8.24
    L1/TEX Cache Throughput             %        57.44
    L2 Cache Throughput                 %        11.52
    SM Active Cycles                cycle 1,688,117.78
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         131,072
    Waves Per SM                                                0.59
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.21
    Achieved Active Warps Per SM           warp         7.82
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.79%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (12.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,894,355
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 128 -B 4096
==PROF== Connected to process 1803229 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 128
Command line number of `thread blocks`: 4096
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4096 blocks, 128 threads per block 
 Elapsed time is : 2.298186 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803229
[1803229] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4096, 1, 1)x(128, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.20
    gpu__time_duration.avg                                    msecond         8.19
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        18.42
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle    9,025,344
    Memory Throughput                   %        11.29
    DRAM Throughput                     %         2.20
    Duration                      msecond         8.19
    L1/TEX Cache Throughput             %        57.44
    L2 Cache Throughput                 %        11.50
    SM Active Cycles                cycle 1,686,400.31
    Compute (SM) Throughput             %         1.85
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   128
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         524,288
    Waves Per SM                                                2.37
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 33.33%                                                                                     
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 639 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 87.7%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           21
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block           16
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.25
    Achieved Active Warps Per SM           warp         7.84
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.75%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (12.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,906,643
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 1
==PROF== Connected to process 1803275 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 1
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 1 blocks, 256 threads per block 
 Elapsed time is : 15.561044 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803275
[1803275] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.11
    gpu__time_duration.avg                                    msecond       165.35
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.91
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle  181,213,081
    Memory Throughput                   %         0.56
    DRAM Throughput                     %         0.11
    Duration                      msecond       165.35
    L1/TEX Cache Throughput             %        57.72
    L2 Cache Throughput                 %         0.59
    SM Active Cycles                cycle 1,676,276.48
    Compute (SM) Throughput             %         0.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             256
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%                                                                                     
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.31
    Achieved Active Warps Per SM           warp         7.88
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.69%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (12.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,962
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 4
==PROF== Connected to process 1803340 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 4
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 4 blocks, 256 threads per block 
 Elapsed time is : 5.546257 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803340
[1803340] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.41
    gpu__time_duration.avg                                    msecond        43.48
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.47
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   47,602,081
    Memory Throughput                   %         2.14
    DRAM Throughput                     %         0.41
    Duration                      msecond        43.48
    L1/TEX Cache Throughput             %        57.62
    L2 Cache Throughput                 %         2.22
    SM Active Cycles                cycle 1,676,739.96
    Compute (SM) Throughput             %         0.35
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%                                                                                      
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.30
    Achieved Active Warps Per SM           warp         7.87
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.7%                                                                                      
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (12.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,034
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 16
==PROF== Connected to process 1803406 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 16
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 16 blocks, 256 threads per block 
 Elapsed time is : 2.959665 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803406
[1803406] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (16, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.10
    gpu__time_duration.avg                                    msecond        16.32
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         9.26
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   17,870,504
    Memory Throughput                   %         5.70
    DRAM Throughput                     %         1.10
    Duration                      msecond        16.32
    L1/TEX Cache Throughput             %        57.59
    L2 Cache Throughput                 %         5.85
    SM Active Cycles                cycle 1,677,857.52
    Compute (SM) Throughput             %         0.93
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%                                                                                     
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.29
    Achieved Active Warps Per SM           warp         7.87
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.71%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (12.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,322
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 64
==PROF== Connected to process 1803450 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 64
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 64 blocks, 256 threads per block 
 Elapsed time is : 2.325044 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803450
[1803450] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (64, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         2.21
    gpu__time_duration.avg                                    msecond         8.23
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %        18.40
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle    8,998,284
    Memory Throughput                   %        11.32
    DRAM Throughput                     %         2.21
    Duration                      msecond         8.23
    L1/TEX Cache Throughput             %        57.45
    L2 Cache Throughput                 %        11.53
    SM Active Cycles                cycle 1,680,698.22
    Compute (SM) Throughput             %         1.86
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          16,384
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%                                                                                     
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        12.28
    Achieved Active Warps Per SM           warp         7.86
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 87.72%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (12.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,771
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 256
==PROF== Connected to process 1803494 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 256
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 256 blocks, 256 threads per block 
 Elapsed time is : 2.505249 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803494
[1803494] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (256, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.10
    gpu__time_duration.avg                                    msecond        16.50
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         9.23
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   18,106,476
    Memory Throughput                   %         5.86
    DRAM Throughput                     %         1.10
    Duration                      msecond        16.50
    L1/TEX Cache Throughput             %        62.13
    L2 Cache Throughput                 %         5.86
    SM Active Cycles                cycle 1,693,900.12
    Compute (SM) Throughput             %         0.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          65,536
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.84
    Achieved Active Warps Per SM           warp        13.98
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 78.16%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (21.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,892,307
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 1024
==PROF== Connected to process 1803559 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 1024
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 1024 blocks, 256 threads per block 
 Elapsed time is : 2.533859 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803559
[1803559] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1024, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.10
    gpu__time_duration.avg                                    msecond        16.50
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         9.26
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   18,055,095
    Memory Throughput                   %         5.88
    DRAM Throughput                     %         1.10
    Duration                      msecond        16.50
    L1/TEX Cache Throughput             %        62.18
    L2 Cache Throughput                 %         5.88
    SM Active Cycles                cycle 1,694,359.90
    Compute (SM) Throughput             %         0.93
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         262,144
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%                                                                                        
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 159 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 78.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.84
    Achieved Active Warps Per SM           warp        13.98
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 78.16%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (21.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,898,451
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 256 -B 4096
==PROF== Connected to process 1803603 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 256
Command line number of `thread blocks`: 4096
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4096 blocks, 256 threads per block 
 Elapsed time is : 2.502468 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803603
[1803603] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4096, 1, 1)x(256, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.10
    gpu__time_duration.avg                                    msecond        16.50
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         9.25
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   18,074,713
    Memory Throughput                   %         5.87
    DRAM Throughput                     %         1.10
    Duration                      msecond        16.50
    L1/TEX Cache Throughput             %        61.98
    L2 Cache Throughput                 %         5.87
    SM Active Cycles                cycle 1,695,292.98
    Compute (SM) Throughput             %         0.93
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   256
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           32.77
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                                4.74
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 20%                                                                                        
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 639 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 78.1%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block           10
    Block Limit Shared Mem                block           32
    Block Limit Warps                     block            8
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        21.87
    Achieved Active Warps Per SM           warp        14.00
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 78.13%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (21.9%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,923,027
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 1
==PROF== Connected to process 1803648 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 1
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 1 blocks, 512 threads per block 
 Elapsed time is : 10.898260 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803648
[1803648] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.11
    gpu__time_duration.avg                                    msecond       167.41
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.92
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle  183,230,318
    Memory Throughput                   %         0.59
    DRAM Throughput                     %         0.11
    Duration                      msecond       167.41
    L1/TEX Cache Throughput             %        63.69
    L2 Cache Throughput                 %         0.59
    SM Active Cycles                cycle 1,697,196.39
    Compute (SM) Throughput             %         0.09
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread             512
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%                                                                                     
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.58
    Achieved Active Warps Per SM           warp        15.73
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.42%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (24.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,889,986
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 4
==PROF== Connected to process 1803715 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 4
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4 blocks, 512 threads per block 
 Elapsed time is : 4.239919 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803715
[1803715] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.36
    gpu__time_duration.avg                                    msecond        49.52
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         3.09
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   54,163,051
    Memory Throughput                   %         1.99
    DRAM Throughput                     %         0.36
    Duration                      msecond        49.52
    L1/TEX Cache Throughput             %        63.59
    L2 Cache Throughput                 %         1.99
    SM Active Cycles                cycle 1,695,647.18
    Compute (SM) Throughput             %         0.31
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           2,048
    Waves Per SM                                                0.01
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%                                                                                      
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp        15.73
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.43%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (24.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,130
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 16
==PROF== Connected to process 1803759 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 16
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 16 blocks, 512 threads per block 
 Elapsed time is : 2.518103 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803759
[1803759] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (16, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.09
    gpu__time_duration.avg                                    msecond        16.55
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         9.23
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   18,129,221
    Memory Throughput                   %         5.94
    DRAM Throughput                     %         1.09
    Duration                      msecond        16.55
    L1/TEX Cache Throughput             %        63.56
    L2 Cache Throughput                 %         5.93
    SM Active Cycles                cycle 1,694,842.19
    Compute (SM) Throughput             %         0.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           8,192
    Waves Per SM                                                0.04
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%                                                                                     
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp        15.72
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.43%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (24.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,515
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 64
==PROF== Connected to process 1803826 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 64
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 64 blocks, 512 threads per block 
 Elapsed time is : 2.516589 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803826
[1803826] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (64, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         1.10
    gpu__time_duration.avg                                    msecond        16.53
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         9.26
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   18,083,983
    Memory Throughput                   %         5.98
    DRAM Throughput                     %         1.10
    Duration                      msecond        16.53
    L1/TEX Cache Throughput             %        63.72
    L2 Cache Throughput                 %         5.96
    SM Active Cycles                cycle 1,696,787.80
    Compute (SM) Throughput             %         0.92
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          32,768
    Waves Per SM                                                0.15
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%                                                                                     
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        24.57
    Achieved Active Warps Per SM           warp        15.72
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 75.43%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (24.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,891,283
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 256
==PROF== Connected to process 1803870 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 256
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 256 blocks, 512 threads per block 
 Elapsed time is : 3.164534 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803870
[1803870] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (256, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.54
    gpu__time_duration.avg                                    msecond        33.53
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         4.64
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   36,725,551
    Memory Throughput                   %         3.08
    DRAM Throughput                     %         0.54
    Duration                      msecond        33.53
    L1/TEX Cache Throughput             %        64.68
    L2 Cache Throughput                 %         3.08
    SM Active Cycles                cycle 1,724,796.04
    Compute (SM) Throughput             %         0.46
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.6 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         131,072
    Waves Per SM                                                0.59
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.62
    Achieved Active Warps Per SM           warp        24.08
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 62.38%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (37.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,894,355
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 1024
==PROF== Connected to process 1803914 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 1024
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 1024 blocks, 512 threads per block 
 Elapsed time is : 3.145267 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803914
[1803914] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1024, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.54
    gpu__time_duration.avg                                    msecond        33.66
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         4.62
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   36,845,190
    Memory Throughput                   %         3.07
    DRAM Throughput                     %         0.54
    Duration                      msecond        33.66
    L1/TEX Cache Throughput             %        64.65
    L2 Cache Throughput                 %         3.07
    SM Active Cycles                cycle 1,725,374.29
    Compute (SM) Throughput             %         0.45
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         524,288
    Waves Per SM                                                2.37
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 33.33%                                                                                     
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 2 full waves and a partial wave of 159 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 33.3% of the total kernel runtime with a lower occupancy of 62.4%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.64
    Achieved Active Warps Per SM           warp        24.09
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 62.36%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (37.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,906,643
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 512 -B 4096
==PROF== Connected to process 1803981 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 512
Command line number of `thread blocks`: 4096
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4096 blocks, 512 threads per block 
 Elapsed time is : 3.164247 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1803981
[1803981] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4096, 1, 1)x(512, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.54
    gpu__time_duration.avg                                    msecond        33.63
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         4.63
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.21
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   36,816,149
    Memory Throughput                   %         3.07
    DRAM Throughput                     %         0.54
    Duration                      msecond        33.63
    L1/TEX Cache Throughput             %        64.61
    L2 Cache Throughput                 %         3.07
    SM Active Cycles                cycle 1,726,695.41
    Compute (SM) Throughput             %         0.46
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                   512
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte           16.38
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       2,097,152
    Waves Per SM                                                9.48
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            5
    Block Limit Shared Mem                block           16
    Block Limit Warps                     block            4
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        37.64
    Achieved Active Warps Per SM           warp        24.09
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 62.36%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (37.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,955,795
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 1
==PROF== Connected to process 1804025 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 1
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%.
==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.
...50%....100% - 13 passes
 GPU configuration: 1 blocks, 1024 threads per block 
 Elapsed time is : 9.783164 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1804025
[1804025] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.10
    gpu__time_duration.avg                                    msecond       180.01
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         0.92
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle  197,118,560
    Memory Throughput                   %         0.70
    DRAM Throughput                     %         0.10
    Duration                      msecond       180.01
    L1/TEX Cache Throughput             %        63.53
    L2 Cache Throughput                 %         0.70
    SM Active Cycles                cycle 1,824,559.43
    Compute (SM) Throughput             %         0.08
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      1
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           1,024
    Waves Per SM                                                0.00
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 99.07%                                                                                     
          The grid for this launch is configured to execute only 1 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        47.74
    Achieved Active Warps Per SM           warp        30.55
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 52.26%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (47.7%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,034
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 4
==PROF== Connected to process 1804094 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 4
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4 blocks, 1024 threads per block 
 Elapsed time is : 4.671373 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1804094
[1804094] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.25
    gpu__time_duration.avg                                    msecond        70.92
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         2.32
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   77,702,103
    Memory Throughput                   %         1.77
    DRAM Throughput                     %         0.25
    Duration                      msecond        70.92
    L1/TEX Cache Throughput             %        63.59
    L2 Cache Throughput                 %         1.77
    SM Active Cycles                cycle 1,824,598.47
    Compute (SM) Throughput             %         0.22
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                      4
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread           4,096
    Waves Per SM                                                0.02
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 96.3%                                                                                      
          The grid for this launch is configured to execute only 4 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        47.73
    Achieved Active Warps Per SM           warp        30.55
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 52.27%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (47.7%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,322
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 16
==PROF== Connected to process 1804138 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 16
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 16 blocks, 1024 threads per block 
 Elapsed time is : 3.382460 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1804138
[1804138] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (16, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.51
    gpu__time_duration.avg                                    msecond        35.44
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         4.64
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.09
    Elapsed Cycles                  cycle   38,806,511
    Memory Throughput                   %         3.53
    DRAM Throughput                     %         0.51
    Duration                      msecond        35.44
    L1/TEX Cache Throughput             %        63.63
    L2 Cache Throughput                 %         3.53
    SM Active Cycles                cycle 1,823,471.70
    Compute (SM) Throughput             %         0.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     16
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          16,384
    Waves Per SM                                                0.07
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 85.19%                                                                                     
          The grid for this launch is configured to execute only 16 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        47.74
    Achieved Active Warps Per SM           warp        30.55
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 52.26%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (47.7%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,890,771
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 64
==PROF== Connected to process 1805079 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 64
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 64 blocks, 1024 threads per block 
 Elapsed time is : 3.175918 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1805079
[1805079] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (64, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.51
    gpu__time_duration.avg                                    msecond        35.47
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         4.64
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   38,851,919
    Memory Throughput                   %         3.53
    DRAM Throughput                     %         0.51
    Duration                      msecond        35.47
    L1/TEX Cache Throughput             %        63.60
    L2 Cache Throughput                 %         3.53
    SM Active Cycles                cycle 1,824,184.31
    Compute (SM) Throughput             %         0.43
    ----------------------- ------------- ------------

    OPT   This kernel grid is too small to fill the available resources on this device, resulting in only 0.3 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                     64
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread          65,536
    Waves Per SM                                                0.30
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 40.74%                                                                                     
          The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        47.75
    Achieved Active Warps Per SM           warp        30.56
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 52.25%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (47.7%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,892,307
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 256
==PROF== Connected to process 1805190 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 256
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 256 blocks, 1024 threads per block 
 Elapsed time is : 4.634684 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1805190
[1805190] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (256, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.25
    gpu__time_duration.avg                                    msecond        72.12
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         2.32
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   78,984,848
    Memory Throughput                   %         1.80
    DRAM Throughput                     %         0.25
    Duration                      msecond        72.12
    L1/TEX Cache Throughput             %        63.68
    L2 Cache Throughput                 %         1.80
    SM Active Cycles                cycle 1,849,163.98
    Compute (SM) Throughput             %         0.21
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                    256
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread         262,144
    Waves Per SM                                                1.19
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 50%                                                                                        
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 1 full waves and a partial wave of 39 thread blocks.   
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 50.0% of the total kernel runtime with a lower occupancy of 31.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        68.83
    Achieved Active Warps Per SM           warp        44.05
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 31.17%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (68.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,898,451
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 1024
==PROF== Connected to process 1805244 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 1024
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 1024 blocks, 1024 threads per block 
 Elapsed time is : 5.052940 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1805244
[1805244] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (1024, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.25
    gpu__time_duration.avg                                    msecond        72.05
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         2.32
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   78,932,267
    Memory Throughput                   %         1.81
    DRAM Throughput                     %         0.25
    Duration                      msecond        72.05
    L1/TEX Cache Throughput             %        63.67
    L2 Cache Throughput                 %         1.81
    SM Active Cycles                cycle 1,849,477.80
    Compute (SM) Throughput             %         0.21
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  1,024
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       1,048,576
    Waves Per SM                                                4.74
    -------------------------------- --------------- ---------------

    OPT   Estimated Speedup: 20%                                                                                        
          A wave of thread blocks is defined as the maximum number of blocks that can be executed in parallel on the    
          target GPU. The number of blocks in a wave depends on the number of multiprocessors and the theoretical       
          occupancy of the kernel. This kernel launch results in 4 full waves and a partial wave of 159 thread blocks.  
          Under the assumption of a uniform execution duration of all thread blocks, the partial wave may account for   
          up to 20.0% of the total kernel runtime with a lower occupancy of 31.2%. Try launching a grid with no         
          partial wave. The overall impact of this tail effect also lessens with the number of full waves executed for  
          a grid. See the Hardware Model                                                                                
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        68.81
    Achieved Active Warps Per SM           warp        44.04
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 31.19%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (68.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    6,923,027
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

ncu --set default --section SourceCounters --section Occupancy --section LaunchStats --section SpeedOfLight --metrics smsp__cycles_active.avg.pct_of_peak_sustained_elapsed,dram__throughput.avg.pct_of_peak_sustained_elapsed,gpu__time_duration.avg ./sobel_gpu -T 1024 -B 4096
==PROF== Connected to process 1805313 (/pscratch/sd/u/usatie/csc746-cp5-gpu-stencil/build/sobel_gpu)
 Read data from the file ../data/zebra-gray-int8-4x 
Command line number of `threads per block`: 1024
Command line number of `thread blocks`: 4096
==PROF== Profiling "sobel_kernel_gpu" - 0: 0%....50%....100% - 13 passes
 GPU configuration: 4096 blocks, 1024 threads per block 
 Elapsed time is : 4.596202 (sec) 
 Wrote the output file ../data/processed-raw-int8-4x-gpu.dat 
==PROF== Disconnected from process 1805313
[1805313] sobel_gpu@127.0.0.1
  sobel_kernel_gpu(const float *, float *, int, int, int) (4096, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 8.0
    Section: Command line profiler metrics
    ----------------------------------------------------- ----------- ------------
    Metric Name                                           Metric Unit Metric Value
    ----------------------------------------------------- ----------- ------------
    dram__throughput.avg.pct_of_peak_sustained_elapsed              %         0.25
    gpu__time_duration.avg                                    msecond        72.06
    smsp__cycles_active.avg.pct_of_peak_sustained_elapsed           %         2.32
    ----------------------------------------------------- ----------- ------------

    Section: GPU Speed Of Light Throughput
    ----------------------- ------------- ------------
    Metric Name               Metric Unit Metric Value
    ----------------------- ------------- ------------
    DRAM Frequency          cycle/nsecond         1.22
    SM Frequency            cycle/nsecond         1.10
    Elapsed Cycles                  cycle   78,984,621
    Memory Throughput                   %         1.80
    DRAM Throughput                     %         0.25
    Duration                      msecond        72.06
    L1/TEX Cache Throughput             %        63.64
    L2 Cache Throughput                 %         1.80
    SM Active Cycles                cycle 1,852,077.41
    Compute (SM) Throughput             %         0.21
    ----------------------- ------------- ------------

    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance 
          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    
          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 

    Section: Launch Statistics
    -------------------------------- --------------- ---------------
    Metric Name                          Metric Unit    Metric Value
    -------------------------------- --------------- ---------------
    Block Size                                                 1,024
    Function Cache Configuration                     CachePreferNone
    Grid Size                                                  4,096
    Registers Per Thread             register/thread              24
    Shared Memory Configuration Size           Kbyte            8.19
    Driver Shared Memory Per Block       Kbyte/block            1.02
    Dynamic Shared Memory Per Block       byte/block               0
    Static Shared Memory Per Block        byte/block               0
    Threads                                   thread       4,194,304
    Waves Per SM                                               18.96
    -------------------------------- --------------- ---------------

    Section: Occupancy
    ------------------------------- ----------- ------------
    Metric Name                     Metric Unit Metric Value
    ------------------------------- ----------- ------------
    Block Limit SM                        block           32
    Block Limit Registers                 block            2
    Block Limit Shared Mem                block            8
    Block Limit Warps                     block            2
    Theoretical Active Warps per SM        warp           64
    Theoretical Occupancy                     %          100
    Achieved Occupancy                        %        68.77
    Achieved Active Warps Per SM           warp        44.01
    ------------------------------- ----------- ------------

    OPT   Estimated Speedup: 31.23%                                                                                     
          This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (68.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

    Section: Source Counters
    ------------------------- ----------- ------------
    Metric Name               Metric Unit Metric Value
    ------------------------- ----------- ------------
    Branch Instructions Ratio           %         0.10
    Branch Instructions              inst    7,021,331
    Branch Efficiency                   %        99.66
    Avg. Divergent Branches                      35.85
    ------------------------- ----------- ------------

    OPT   Estimated Speedup: 0%                                                                                         
          This kernel has uncoalesced global accesses resulting in a total of 319973224 excessive sectors (87% of the   
          total 365762912 sectors). Check the L2 Theoretical Sectors Global Excessive table for the primary source      
          locations. The CUDA Programming Guide                                                                         
          (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#device-memory-accesses) had additional      
          information on reducing uncoalesced device memory accesses.                                                   

